<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Neural Networks Structure</title>
<!-- ajax -->
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/themes/prism-tomorrow.min.css'>
<!-- bootstrap -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<!-- prims plugin styles -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/autolinker/prism-autolinker.min.css" rel="stylesheet">
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/command-line/prism-command-line.min.css" rel="stylesheet">
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet">
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/toolbar/prism-toolbar.min.css" rel="stylesheet">
<style>
a,
a:hover,
a:focus {
	text-decoration: none;
}

pre {
	margin-bottom: 1.3rem !important;
}
.dark-mode {
	background-color: black;
	color: #aaaaaa;
}

.dark-mode a {
	color: royalblue;
}

.dark-mode .list-group-item {
	background-color: #212529;
	color: #aaaaaa;
}

.dark-mode .group-child {
	background-color: #3a3a3a !important;
}

.dark-mode a.list-group-item:focus,
.dark-mode a.list-group-item:hover,
.dark-mode button.list-group-item:focus,
.dark-mode button.list-group-item:hover {
	background-color: #555555;
	color: #bdc0c4;
}
.breadcrumb a,
.breadcrumb a:hover,
.breadcrumb a:focus {
	text-decoration: none;
}

.breadcrumb-item+.breadcrumb-item::before {
	content: '> ';
}

.dark-mode .breadcrumb {
	background-color: #212529;
}

.dark-mode .breadcrumb a {
	color: #bdc0c4;
}

.dark-mode .breadcrumb a:hover,
.dark-mode .breadcrumb a:focus {
	text-decoration: none;
	color: #777777;
}
.just-padding {
  padding: 15px;
}

a.list-group-item:focus,
a.list-group-item:hover,
button.list-group-item:focus,
button.list-group-item:hover {
	color: #555;
	text-decoration: none;
	background-color: #dfdfdf;
}

.group-child {
	background-color: #f0f0f0 !important;
}

.list-group.list-group-root {
  padding: 0;
  overflow: hidden;
}

.list-group.list-group-root .list-group {
  margin-bottom: 0;
}

.list-group.list-group-root .list-group-item {
  border-radius: 0;
  border-width: 1px 0 0 0;
}

.list-group.list-group-root > .list-group-item:first-child {
  border-top-width: 0;
}

.list-group.list-group-root > .list-group > .list-group-item {
  padding-left: 30px;
}

.list-group.list-group-root > .list-group > .list-group > .list-group-item {
  padding-left: 45px;
}

.list-group-item .glyphicon {
  margin-right: 5px;
}
.pager .top {
	float: center;
}

.dark-mode .page-link {
	color: #bdc0c4;
	background-color: #212529;
	border: 1px solid #616161;
}

.dark-mode .page-link .disabled li > a {
	color: #bdc0c4;
	background-color: #212529;
	border: 1px solid #616161;
}

.dark-mode .pager li > a,
.dark-mode .pager li > span {
	color: #bdc0c4;
	background-color: #212529;
	border: 1px solid #616161;
}

.dark-mode .pager li > a:hover,
.dark-mode .pager li > a:focus,
.dark-mode .pager li > span:hover {
	background-color: #555555;
	color: #bdc0c4;
}

.dark-mode .pager .disabled a,
.dark-mode .pager .disabled a:hover,
.dark-mode .pager .disabled a:focus {
	color: #6c757d;
	background-color: #212529;
	border: 1px solid #616161;
}
/* prism overrides */
div.code-toolbar>.toolbar a,
div.code-toolbar>.toolbar button,
div.code-toolbar>.toolbar span {
	margin-left: 0.7rem;
}
h1:hover .anchor .octicon-link, h2:hover .anchor .octicon-link, h3:hover .anchor .octicon-link, h4:hover .anchor .octicon-link, h5:hover .anchor .octicon-link, h6:hover .anchor .octicon-link {
	visibility: visible;
}

h1:hover .anchor .octicon-link, h2:hover .anchor .octicon-link, h3:hover .anchor .octicon-link, h4:hover .anchor .octicon-link, h5:hover .anchor .octicon-link, h6:hover .anchor .octicon-link {
	visibility: visible;
}

h1 .octicon-link, h2 .octicon-link, h3 .octicon-link, h4 .octicon-link, h5 .octicon-link, h6 .octicon-link {
	color: var(--color-text-primary);
	visibility: hidden;
}

h1 .octicon-link, h2 .octicon-link, h3 .octicon-link, h4 .octicon-link, h5 .octicon-link, h6 .octicon-link {
	color: var(--color-text-primary);
	visibility: hidden;
}

.octicon {
    fill: currentColor;
}
</style>
</head>
<body class="container">
<ol class="breadcrumb">
<li class="breadcrumb-item"><a title="Shortcut: ALT + SHIFT + 1" accesskey="1" href="/">Home</a></li>
<li class="breadcrumb-item"><a title="Shortcut: ALT + SHIFT + 2" accesskey="2" href="/10.0.html">Machine Learning</a></li>
<li class="breadcrumb-item"><a title="Shortcut: ALT + SHIFT + 3" accesskey="3" href="/10.1.0.html">Neural Networks</a></li>
<li class="breadcrumb-item active" Neural Networks Structure breadcrumb-item active>Neural Networks Structure</li>
</ol>
<h2>
<a id="Neural-Networks-Structure" class="anchor" aria-hidden="true" href="#Neural-Networks-Structure">
Neural Networks Structure
<svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">
<path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z">
</path>
</svg>
</a>
</h2>
<div class="comment-style" >
Real biological neurons take many inputs, not just one.<br />
Similarly, we simply combine input signals by adding them up, and the
resultant sum is the input to the sigmoid function which controls the output.<br />
This reflects how real neurons work. The following diagram illustrates this
idea of combining inputs and then applying the threshold to the combined sum:<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/sigmoid-function-demonstration-in-a-node.png" alt="sigmoid function demonstration in a node" loading="lazy">
<br />
If the combined signal is not large enough then the effect of the sigmoid
threshold function is to suppress the output signal. If the sum x is large
enough, the effect of the sigmoid is to fire the neuron. Interestingly, if only
one of the several inputs is large and the rest small, this may be enough to
fire the neuron. What's more, the neuron can fire if some of the inputs
are individually almost, but not quite, large enough because when combined the
signal is large enough to overcome the threshold.<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/three-layers-neural-networks-sample-without-weights.png" alt="three layers neural networks sample without weights" loading="lazy">
<br />
The following diagram again shows the connected nodes, but this time a weight
is shown associated with each connection. A low weight will de-emphasise a
signal, and a high weight will amplify it.<br />
<br />
The weight w2,3 is simply the weight associated with the signal that passed
between node 2 in a layer to node 3 in the next layer. So w1,2 is the weight
that diminishes or amplifies the signal between node 1 and node 2 in the next
layer.<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/three-layers-neural-networks-sample-with-weights.png" alt="three layers neural networks sample with weights" loading="lazy">
<br />
You might reasonably challenge this design and ask yourself why each node
should connect to every other node in the previous and next layer. They
don't have to and you could connect them in all sorts of creative ways. We
don't because the uniformity of this full connectivity is actually easier
to encode as computer instructions, and because there shouldn't be any big
harm in having a few more connections than the absolute minimum that might be
needed for solving a specific task. The learning process will de-emphasise
those few extra connections if they aren't actually needed.<br />
<br />
What do we mean by this? It means that as the network learns to improve its
outputs by refining the link weights inside the network, some weights become
zero or close to zero. Zero, or almost zero, weights means those links
don't contribute to the network because signals don't pass. A zero
weight means the signals are multiplied by zero, which results in zero, so the
link is effectively broken.<br />
<br />
we'll try doing the workings out with a smaller neural network with only 2
layers, each with 2 neurons, as shown below:<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/two-layers-neural-networks-without-weights.png" alt="two layers neural networks without weights" loading="lazy">
<br />
Let's imagine the two inputs are 1.0 and 0.5. The following shows these inputs
entering this smaller neural network.<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/two-layers-neural-networks-with-inputs.png" alt="two layers neural networks with inputs" loading="lazy">
<br />
Just as before, each node turns the sum of the inputs into an output using an
activation function. We'll also use the sigmoid function that we saw before,
where x is the sum of incoming signals to a neuron, and y is the output of
that neuron.<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/sigmoid-function.png" alt="sigmoid function" loading="lazy">
<br />
The x in this function is the combined input into a node. That combination was
the raw outputs from the connected nodes in the previous layer, but moderated
by the link weights.<br />
<br />
The following diagram shows all these numbers now marked.<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/two-layers-neural-networks-with-weights.png" alt="two layers neural networks with weights" loading="lazy">
<br />
The first layer of nodes is the input layer, and it doesn't do anything other
than represent the input signals. That is, the input nodes don't apply an
activation function to the input.<br />
<br />
The following diagram is like the one we saw previously but now includes the
need to moderate the incoming signals with the link weights.<br />
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/node-with-input-and-weights.png" alt="node with input and weights" loading="lazy">
<br />
So let's first focus on node 1 in the layer 2.<br />
<br />
The combined moderated input is:<br />
<br />
x = (output from first node * link weight) + (output from second node * link weight)
x = (1.0 * 0.9) + (0.5 * 0.3)
x = 0.9 + 0.15
x = 1.05
<br />
If we didn't moderate the signal, we'd have a very simple addition of the
signals 1.0 + 0.5, but we don't want that. It is the weights that do the
learning in a neural networks as they are iteratively refined to give better
and better results.<br />
<br />
We can now, finally, calculate that node's output using the activation
function.<br />
<br />
x = (1.0 * 0.2) + (0.5 * 0.8)
x = 0.2 + 0.4
x = 0.6
<br />
So the node's output using the sigmoid activation function would be:<br />
<br />
y = 1/(1 + 0.5488) = 1/(1.5488)
y = 0.6457
<br />
<img class="img-responsive" src="/machine-learning/neural-networks/two-layers-neural-networks-with-outputs.png" alt="two layers neural networks with outputs" loading="lazy">
<br />
</div>
<ul class="pager">
<li class="previous"><a title="Shortcut: ALT + SHIFT + B" accesskey="B" href="/machine-learning/neural-networks">previous page</a></li>
<li class="top"><a title="Shortcut: ALT + SHIFT + T" accesskey="T" href="/">top page</a></li>
<li class="next"><a title="Shortcut: ALT + SHIFT + F" accesskey="F" href="/electornics">next page</a></li>
</ul>
<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<!-- bootstrap -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
<!-- prism js -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/prism.min.js'></script>
<!-- prism plugins -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/toolbar/prism-toolbar.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/autolinker/prism-autolinker.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/command-line/prism-command-line.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/normalize-whitespace/prism-normalize-whitespace.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/remove-initial-line-feed/prism-remove-initial-line-feed.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/plugins/show-language/prism-show-language.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.22.0/components/prism-bash.min.js"></script>
<script>
function darkmode(manual) {
	const hours = new Date().getHours();
	const isNight = !(hours > 6 && hours < 20);
	var bodystyle = document.body;
	if (isNight || manual) {
		bodystyle.classList.add("dark-mode");
	} else {
		bodystyle.classList.remove("dark-mode");
	}
}
darkmode();
$(function() {
  $('.list-group-item').on('click', function() {
    $('.glyphicon', this)
      .toggleClass('glyphicon-chevron-right')
      .toggleClass('glyphicon-chevron-down');
  });
});
</script>
</body>
</html>
